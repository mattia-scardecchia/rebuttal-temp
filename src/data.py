import json
import math
import os
import logging
from typing import Optional

import numpy as np
import torch
import torch.nn as nn
from torchvision import datasets, transforms

from src.utils import DTYPE

logger = logging.getLogger(__name__)


class SignActivation(nn.Module):
    def forward(self, x):
        return torch.sign(x)


def load_balanced_dataset(save_dir: str):
    """Load dataset as saved by dump_balanced_dataset. \\
    :param save_dir: directory where the dataset is saved. \\
    :return: inputs, targets, metadata.
    """
    with open(os.path.join(save_dir, "metadata.json"), "r") as f:
        metadata = json.load(f)
    with open(os.path.join(save_dir, "inputs.npy"), "rb") as f:
        inputs = np.load(f)
    with open(os.path.join(save_dir, "targets.npy"), "rb") as f:
        targets = np.load(f)
    with open(os.path.join(save_dir, "class_prototypes.npy"), "rb") as f:
        class_prototypes = np.load(f)
    return inputs, targets, metadata, class_prototypes


def dump_balanced_dataset(inputs, targets, metadata, save_dir: str, class_prototypes):
    """Dump dataset as generated by generate_balanced_dataset."""
    os.makedirs(save_dir, exist_ok=True)
    with open(os.path.join(save_dir, "metadata.json"), "w") as f:
        json.dump(metadata, f)
    with open(os.path.join(save_dir, "inputs.npy"), "wb") as f:
        np.save(f, inputs)
    with open(os.path.join(save_dir, "targets.npy"), "wb") as f:
        np.save(f, targets)
    with open(os.path.join(save_dir, "class_prototypes.npy"), "wb") as f:
        np.save(f, class_prototypes)


def generate_balanced_dataset(
    N: int,
    P: int,
    C: int,
    p: float,
    rng: np.random.Generator,
    prototypes: Optional[np.ndarray],
):
    """Generates a balanced dataset with P*C patterns and C classes. Sample C N-dimensional
    binary (+/- 1) class prototypes and flip a fraction p of their bits P times to generate
    the patterns."""
    class_prototypes = (
        prototypes.copy()
        if prototypes is not None
        else rng.choice([-1, 1], size=(C, N))
    )
    inputs = np.zeros((P * C, N), dtype=np.int8)
    for c in range(C):
        inputs[c * P : (c + 1) * P] = class_prototypes[c]
        flips = 2 * rng.binomial(1, 1 - p, size=(P, N)) - 1
        inputs[c * P : (c + 1) * P] *= flips
    targets = np.repeat(np.eye(C), P, axis=0)
    metadata = {"N": N, "P": P, "C": C, "p": p}
    return inputs, targets, metadata, class_prototypes


def get_balanced_dataset(
    N: int,
    P: int,
    C: int,
    p: float,
    save_dir: str,
    prototypes: Optional[np.ndarray] = None,
    rng: Optional[np.random.Generator] = None,
    shuffle: bool = True,
    load_if_available: bool = True,
    dump: bool = True,
):
    """Generates a balanced dataset with P*C patterns and C classes. Sample C N-dimensional
    binary (+/- 1) class prototypes and flip a fraction p of their bits P times to generate
    the patterns. \\
    Dump the class prototypes, the generated pairs (pattern, class), and a metadata file which
    contains the dataset parameters. \\
    :param N: input dimensionality. \\
    :param P: number of patterns per class. \\
    :param C: number of classes. \\
    :param p: probability of flipping a bit from class prototypes. \\
    :param prototypes: if not None, use these prototypes instead of generating new ones. \\
    :param save_dir: directory to save the dataset. \\
    :param load_if_available: if True, load the dataset from save_dir if metadata (and prototypes) match. \\
    :param dump: if True, dump the dataset to save_dir.
    """
    if load_if_available and os.path.exists(save_dir):
        inputs, targets, metadata, class_prototypes = load_balanced_dataset(save_dir)
        if (
            metadata["N"] == N
            and metadata["P"] == P
            and metadata["C"] == C
            and metadata["p"] == p
            and (prototypes is None or np.array_equal(class_prototypes, prototypes))
        ):
            return inputs, targets, metadata, class_prototypes

    rng = np.random.default_rng() if rng is None else rng
    inputs, targets, metadata, class_prototypes = generate_balanced_dataset(
        N, P, C, p, rng, prototypes
    )
    if shuffle:
        indices = rng.permutation(P * C)
        inputs = inputs[indices]
        targets = targets[indices]
    if dump:
        dump_balanced_dataset(inputs, targets, metadata, save_dir, class_prototypes)
    return inputs, targets, metadata, class_prototypes


def load_synthetic_dataset(
    N,
    P,
    C,
    p,
    eval_samples_per_class,
    rng,
    train_data_dir,
    test_data_dir,
    device,
):
    train_inputs, train_targets, train_metadata, train_class_prototypes = (
        get_balanced_dataset(
            N,
            P,
            C,
            p,
            train_data_dir,
            None,
            rng,
            shuffle=False,
            load_if_available=True,
            dump=True,
        )
    )
    eval_inputs, eval_targets, eval_metadata, eval_class_prototypes = (
        get_balanced_dataset(
            N,
            eval_samples_per_class,
            C,
            p,
            test_data_dir,
            train_class_prototypes,
            rng,
            shuffle=False,
            load_if_available=True,
            dump=True,
        )
    )
    train_inputs = torch.tensor(train_inputs, dtype=torch.float32).to(device)
    train_targets = torch.tensor(train_targets, dtype=torch.float32).to(device)
    eval_inputs = torch.tensor(eval_inputs, dtype=torch.float32).to(device)
    eval_targets = torch.tensor(eval_targets, dtype=torch.float32).to(device)

    return (
        train_inputs,
        train_targets,
        eval_inputs,
        eval_targets,
        train_metadata,
        train_class_prototypes,
        eval_metadata,
        eval_class_prototypes,
    )


def prepare_vision_data(
    dataset_cls,
    num_labels,
    num_samples_train,
    num_samples_eval,
    N,
    binarize,
    seed,
    shuffle=True,
    project=True,
    noise=0.0,
):
    torch.manual_seed(seed)
    transform = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Lambda(lambda x: x.view(-1)),
        ]
    )
    train_dataset = dataset_cls(
        root="./data", train=True, download=True, transform=transform
    )
    eval_dataset = dataset_cls(
        root="./data", train=False, download=True, transform=transform
    )
    train_sample_shape = train_dataset[0][0].shape
    train_sample_size = math.prod(train_sample_shape)

    # Downsample the datasets
    train_perm = (
        torch.randperm(len(train_dataset))
        if shuffle
        else torch.arange(len(train_dataset))
    )
    train_indices = train_perm[:num_samples_train]
    train_images = torch.stack([train_dataset[i][0] for i in train_indices])
    train_labels = torch.tensor([train_dataset[i][1] for i in train_indices])
    eval_perm = (
        torch.randperm(len(eval_dataset))
        if shuffle
        else torch.arange(len(eval_dataset))
    )
    eval_indices = eval_perm[:num_samples_eval]
    eval_images = torch.stack([eval_dataset[i][0] for i in eval_indices])
    eval_labels = torch.tensor([eval_dataset[i][1] for i in eval_indices])

    # Sort samples by class
    sort_idx = torch.argsort(eval_labels)
    eval_labels = eval_labels[sort_idx]
    eval_images = eval_images[sort_idx]
    sort_idx = torch.argsort(train_labels)
    train_labels = train_labels[sort_idx]
    train_images = train_images[sort_idx]

    # Convert labels to one-hot encoding
    train_labels = torch.eye(num_labels)[train_labels]
    eval_labels = torch.eye(num_labels)[eval_labels]

    # Random linear projection and binarization
    projection_matrix = None
    if project:
        projection_matrix = torch.randn(train_sample_size, N)
        train_images = train_images @ projection_matrix
        eval_images = eval_images @ projection_matrix
    if not binarize and noise > 0:
        logger.warning("binarize is false and noise > 0. skipping")
    if binarize:
        # train_median = train_images.median(dim=0, keepdim=True).values
        # eval_median = eval_images.median(dim=0, keepdim=True).values
        # train_images = torch.sign(train_images - train_median)
        # eval_images = torch.sign(eval_images - eval_median)
        train_images = torch.sign(train_images)
        eval_images = torch.sign(eval_images)
        if noise > 0:
            flip_mask_train = torch.rand_like(train_images).lt(noise)
            flip_mask_eval = torch.rand_like(eval_images).lt(noise)
            train_images = train_images * torch.where(flip_mask_train, -1, 1)
            eval_images = eval_images * torch.where(flip_mask_eval, -1, 1)
    else:
        train_images = (train_images - train_images.min()) / (
            train_images.max() - train_images.min()
        )
        eval_images = (eval_images - eval_images.min()) / (
            eval_images.max() - eval_images.min()
        )

    return (
        train_images.to(DTYPE),
        train_labels.to(DTYPE),
        eval_images.to(DTYPE),
        eval_labels.to(DTYPE),
        projection_matrix,
    )


def prepare_mnist(
    num_samples_train,
    num_samples_eval,
    N,
    binarize,
    seed,
    shuffle=True,
    project=True,
    noise=0.0,
):
    return prepare_vision_data(
        datasets.MNIST,
        10,
        num_samples_train,
        num_samples_eval,
        N,
        binarize,
        seed,
        shuffle,
        project,
        noise=noise,
    )


def prepare_fashionmnist(
    num_samples_train, num_samples_eval, N, binarize, seed, shuffle=True, project=True
):
    return prepare_vision_data(
        datasets.FashionMNIST,
        10,
        num_samples_train,
        num_samples_eval,
        N,
        binarize,
        seed,
        shuffle,
        project,
    )


def prepare_cifar(
    num_samples_train, num_samples_eval, N, binarize, seed, shuffle=True, project=True
):
    return prepare_vision_data(
        datasets.CIFAR10,
        10,
        num_samples_train,
        num_samples_eval,
        N,
        binarize,
        seed,
        shuffle,
        project,
    )


def prepare_svhn(
    num_samples_train, num_samples_eval, N, binarize, seed, shuffle=True, project=True
):
    return prepare_vision_data(
        datasets.SVHN,
        10,
        num_samples_train,
        num_samples_eval,
        N,
        binarize,
        seed,
        shuffle,
        project,
    )


@torch.no_grad()
def prepare_hm_data(
    D,
    C,
    P,
    P_eval,
    M,
    L,
    width,
    hidden_activation,
    seed,
    binarize,
):
    """
    Prepares synthetic data using two teacher networks:
      - teacher_linear: a linear model (D -> C) for label generation.
      - teacher_mlp: an MLP with L hidden layers and final output dimension M.

    Parameters:
        D (int): Latent dimension.
        C (int): Number of classes.
        P (int): Number of patterns per class (total samples = P * C).
        M (int): Output dimension of the teacher MLP.
        L (int): Number of hidden layers in teacher MLP.
        width (int or list[int]): Hidden layer width(s). If int, used for all layers.
        activation (nn.Module or list[nn.Module]): Activation function(s) for hidden layers.
        seed (int): Random seed.

    Returns:
        latent_inputs (torch.Tensor): Latent inputs (P * C, D), sorted by predicted class.
        projected_inputs (torch.Tensor): Teacher MLP outputs, shape (P * C, M).
        labels (torch.Tensor): One-hot labels, shape (P * C, C).
        teacher_linear (nn.Module): The linear teacher network.
        teacher_mlp (nn.Module): The MLP teacher network.
    """
    torch.manual_seed(seed)

    # Instantiate the teacher_linear model.
    teacher_linear = nn.Linear(D, C)

    # Build the teacher_mlp.
    if isinstance(width, int):
        widths = [width] * L
    else:
        assert len(width) == L, "Length of width list must equal L."
        widths = width

    if not isinstance(hidden_activation, list):
        activations = [hidden_activation] * L
    else:
        assert len(hidden_activation) == L, "Length of activation list must equal L."
        activations = hidden_activation

    mlp_layers = []
    in_features = D
    for i in range(L):
        mlp_layers.append(nn.Linear(in_features, widths[i]))
        mlp_layers.append(nn.LayerNorm(widths[i]))
        mlp_layers.append(activations[i])
        in_features = widths[i]
    mlp_layers.append(nn.Linear(in_features, M))
    if binarize:
        mlp_layers.append(SignActivation())
    teacher_mlp = nn.Sequential(*mlp_layers)

    total_samples = (P + P_eval) * C
    latent_inputs = torch.randn(total_samples, D)
    logits = teacher_linear(latent_inputs)
    preds = torch.argmax(logits, dim=1)
    projected_inputs = teacher_mlp(latent_inputs)

    # split the data into training and evaluation sets
    latent_inputs_train = latent_inputs[: P * C]
    logits_train = logits[: P * C]
    preds_train = preds[: P * C]
    projected_inputs_train = projected_inputs[: P * C]
    latent_inputs_eval = latent_inputs[P * C :]
    logits_eval = logits[P * C :]
    preds_eval = preds[P * C :]
    projected_inputs_eval = projected_inputs[P * C :]

    # Sort samples by predicted class.
    sort_idx = torch.argsort(preds_train)
    train_inputs = projected_inputs_train[sort_idx]
    train_preds = preds_train[sort_idx]
    train_labels = torch.eye(C)[train_preds]
    sort_idx = torch.argsort(preds_eval)
    eval_inputs = projected_inputs_eval[sort_idx]
    eval_preds = preds_eval[sort_idx]
    eval_labels = torch.eye(C)[eval_preds]

    return (
        train_inputs.to(dtype=DTYPE),
        train_labels.to(dtype=DTYPE),
        eval_inputs.to(dtype=DTYPE),
        eval_labels.to(dtype=DTYPE),
        teacher_linear,
        teacher_mlp,
    )
